{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "\n",
    "\n",
    "# Check tensorflow is the backend\n",
    "print(keras.backend.backend())\n",
    "keras.backend.image_dim_ordering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in lines[1:]:\n",
    "    \n",
    "    source_path = line[0]\n",
    "    filename = source_path.split(\"/\")[-1]\n",
    "    current_path = 'data/IMG/' + filename\n",
    "    \n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "\n",
    "\n",
    "print(len(images), len(measurements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Training Data\n",
    "\n",
    "lines = []\n",
    "with open('extra_data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "                \n",
    "for line in lines[1:]:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split(\"/\")[-1]\n",
    "    current_path = 'extra_data/IMG/' + filename\n",
    "    \n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    \n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation \n",
    "\n",
    "augmented_images, augmented_measurements = [], []\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    \n",
    "    # Flip each image and measurement\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement * -1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Setup\n",
    "\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (NVIDIA) Architecture\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Normalisation Layer\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "\n",
    "# Cropping Layer\n",
    "model.add(Cropping2D(cropping=((70, 25), (0,0))))\n",
    "\n",
    "# Convolution Layers\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"relu\"))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss for each epoch\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model mean squared error loss\")\n",
    "plt.ylabel(\"mean squared error loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"training set\", \"validation set\"], loc=\"upper right\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
